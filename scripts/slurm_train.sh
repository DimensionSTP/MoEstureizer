#!/bin/bash
#SBATCH --job-name=train_job
#SBATCH --partition=8gpu
#SBATCH --gres=gpu:8
#SBATCH --nodelist=gpu-8-003
#SBATCH --output=logs/train_output.log
#SBATCH --error=logs/train_error.log

cd ~/merge-up-slm

module add compilers/cuda/12.4 compilers/gcc/10.2.0 libraries/nccl/2.21.5
source activate myenv

data_type="conversational"
split_ratio=1e-2
is_strict_split=True
dataset_name="tulu"
is_sft=True
is_preprocessed=False
strategy="deepspeed"
upload_user="HuggingFaceTB"
model_type="SmolLM2-360M-Instruct"
left_padding=False
is_enable_thinking=False
initialize=True
moe_type="moesturized"
num_experts=8
num_experts_per_tok=3
norm_topk_prob=True
router_aux_loss_coef=0.001
model_detail="${model_type}-${moe_type}-experts_${num_experts}-tok_${num_experts_per_tok}"
is_quantized=False
is_peft=False
max_length=4096
is_bf16=True
batch_size=16
eval_batch_size=16
gradient_accumulation_steps=1
lr=1e-4
weight_decay=1e-1
warmup_ratio=5e-2
epoch=2
step=250
workers_ratio=8
use_all_workers=False

if [ "$strategy" = "deepspeed" ]; then
    deepspeed main.py mode=train \
        data_type=$data_type \
        split_ratio=$split_ratio \
        is_strict_split=$is_strict_split \
        dataset_name=$dataset_name \
        is_sft=$is_sft \
        is_preprocessed=$is_preprocessed \
        strategy=$strategy \
        upload_user=$upload_user \
        model_type=$model_type \
        left_padding=$left_padding \
        is_enable_thinking=$is_enable_thinking \
        initialize=$initialize \
        moe_type=$moe_type \
        num_experts=$num_experts \
        num_experts_per_tok=$num_experts_per_tok \
        norm_topk_prob=$norm_topk_prob \
        router_aux_loss_coef=$router_aux_loss_coef \
        model_detail=$model_detail \
        is_quantized=$is_quantized \
        is_peft=$is_peft \
        max_length=$max_length \
        is_bf16=$is_bf16 \
        batch_size=$batch_size \
        eval_batch_size=$eval_batch_size \
        gradient_accumulation_steps=$gradient_accumulation_steps \
        lr=$lr \
        weight_decay=$weight_decay \
        warmup_ratio=$warmup_ratio \
        epoch=$epoch \
        step=$step \
        workers_ratio=$workers_ratio \
        use_all_workers=$use_all_workers
else
    python main.py mode=train \
        data_type=$data_type \
        split_ratio=$split_ratio \
        is_strict_split=$is_strict_split \
        dataset_name=$dataset_name \
        is_sft=$is_sft \
        is_preprocessed=$is_preprocessed \
        strategy=$strategy \
        upload_user=$upload_user \
        model_type=$model_type \
        left_padding=$left_padding \
        is_enable_thinking=$is_enable_thinking \
        initialize=$initialize \
        moe_type=$moe_type \
        num_experts=$num_experts \
        num_experts_per_tok=$num_experts_per_tok \
        norm_topk_prob=$norm_topk_prob \
        router_aux_loss_coef=$router_aux_loss_coef \
        model_detail=$model_detail \
        is_quantized=$is_quantized \
        is_peft=$is_peft \
        max_length=$max_length \
        is_bf16=$is_bf16 \
        batch_size=$batch_size \
        eval_batch_size=$eval_batch_size \
        gradient_accumulation_steps=$gradient_accumulation_steps \
        lr=$lr \
        weight_decay=$weight_decay \
        warmup_ratio=$warmup_ratio \
        epoch=$epoch \
        step=$step \
        workers_ratio=$workers_ratio \
        use_all_workers=$use_all_workers
fi
